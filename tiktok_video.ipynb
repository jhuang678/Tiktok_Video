{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jeffreyhuang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeffreyhuang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jeffreyhuang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jeffreyhuang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeffreyhuang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import warnings\n",
    "from matplotlib import MatplotlibDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=MatplotlibDeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Pre-Processing and Basic EDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Information"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19382, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   # claim_status    video_id  video_duration_sec  \\\n0  1        claim  7017666017                  59   \n1  2        claim  4014381136                  32   \n2  3        claim  9859838091                  31   \n3  4        claim  1866847991                  25   \n4  5        claim  7105231098                  19   \n\n                                                                                                                    video_transcription_text  \\\n0                                          someone shared with me that drone deliveries are already happening and will become common by 2025   \n1                                someone shared with me that there are more microorganisms in one teaspoon of soil than people on the planet   \n2  someone shared with me that american industrialist andrew carnegie had a net worth of $475 million usd, worth over $300 billion usd today   \n3        someone shared with me that the metro of st. petersburg, with an average depth of hundred meters, is the deepest metro in the world   \n4           someone shared with me that the number of businesses allowing employees to bring pets to the workplace has grown by 6% worldwide   \n\n  verified_status author_ban_status  video_view_count  video_like_count  \\\n0    not verified      under review          343296.0           19425.0   \n1    not verified            active          140877.0           77355.0   \n2    not verified            active          902185.0           97690.0   \n3    not verified            active          437506.0          239954.0   \n4    not verified            active           56167.0           34987.0   \n\n   video_share_count  video_download_count  video_comment_count  \n0              241.0                   1.0                  0.0  \n1            19034.0                1161.0                684.0  \n2             2858.0                 833.0                329.0  \n3            34812.0                1234.0                584.0  \n4             4110.0                 547.0                152.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>claim_status</th>\n      <th>video_id</th>\n      <th>video_duration_sec</th>\n      <th>video_transcription_text</th>\n      <th>verified_status</th>\n      <th>author_ban_status</th>\n      <th>video_view_count</th>\n      <th>video_like_count</th>\n      <th>video_share_count</th>\n      <th>video_download_count</th>\n      <th>video_comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>claim</td>\n      <td>7017666017</td>\n      <td>59</td>\n      <td>someone shared with me that drone deliveries are already happening and will become common by 2025</td>\n      <td>not verified</td>\n      <td>under review</td>\n      <td>343296.0</td>\n      <td>19425.0</td>\n      <td>241.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>claim</td>\n      <td>4014381136</td>\n      <td>32</td>\n      <td>someone shared with me that there are more microorganisms in one teaspoon of soil than people on the planet</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>140877.0</td>\n      <td>77355.0</td>\n      <td>19034.0</td>\n      <td>1161.0</td>\n      <td>684.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>claim</td>\n      <td>9859838091</td>\n      <td>31</td>\n      <td>someone shared with me that american industrialist andrew carnegie had a net worth of $475 million usd, worth over $300 billion usd today</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>902185.0</td>\n      <td>97690.0</td>\n      <td>2858.0</td>\n      <td>833.0</td>\n      <td>329.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>claim</td>\n      <td>1866847991</td>\n      <td>25</td>\n      <td>someone shared with me that the metro of st. petersburg, with an average depth of hundred meters, is the deepest metro in the world</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>437506.0</td>\n      <td>239954.0</td>\n      <td>34812.0</td>\n      <td>1234.0</td>\n      <td>584.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>claim</td>\n      <td>7105231098</td>\n      <td>19</td>\n      <td>someone shared with me that the number of businesses allowing employees to bring pets to the workplace has grown by 6% worldwide</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>56167.0</td>\n      <td>34987.0</td>\n      <td>4110.0</td>\n      <td>547.0</td>\n      <td>152.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tiktok.csv')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                  #      video_id  video_duration_sec  video_view_count  \\\ncount  19382.000000  1.938200e+04        19382.000000      19084.000000   \nmean    9691.500000  5.627454e+09           32.421732     254708.558688   \nstd     5595.245794  2.536440e+09           16.229967     322893.280814   \nmin        1.000000  1.234959e+09            5.000000         20.000000   \n25%     4846.250000  3.430417e+09           18.000000       4942.500000   \n50%     9691.500000  5.618664e+09           32.000000       9954.500000   \n75%    14536.750000  7.843960e+09           47.000000     504327.000000   \nmax    19382.000000  9.999873e+09           60.000000     999817.000000   \n\n       video_like_count  video_share_count  video_download_count  \\\ncount      19084.000000       19084.000000          19084.000000   \nmean       84304.636030       16735.248323           1049.429627   \nstd       133420.546814       32036.174350           2004.299894   \nmin            0.000000           0.000000              0.000000   \n25%          810.750000         115.000000              7.000000   \n50%         3403.500000         717.000000             46.000000   \n75%       125020.000000       18222.000000           1156.250000   \nmax       657830.000000      256130.000000          14994.000000   \n\n       video_comment_count  \ncount         19084.000000  \nmean            349.312146  \nstd             799.638865  \nmin               0.000000  \n25%               1.000000  \n50%               9.000000  \n75%             292.000000  \nmax            9599.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>video_id</th>\n      <th>video_duration_sec</th>\n      <th>video_view_count</th>\n      <th>video_like_count</th>\n      <th>video_share_count</th>\n      <th>video_download_count</th>\n      <th>video_comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>19382.000000</td>\n      <td>1.938200e+04</td>\n      <td>19382.000000</td>\n      <td>19084.000000</td>\n      <td>19084.000000</td>\n      <td>19084.000000</td>\n      <td>19084.000000</td>\n      <td>19084.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9691.500000</td>\n      <td>5.627454e+09</td>\n      <td>32.421732</td>\n      <td>254708.558688</td>\n      <td>84304.636030</td>\n      <td>16735.248323</td>\n      <td>1049.429627</td>\n      <td>349.312146</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5595.245794</td>\n      <td>2.536440e+09</td>\n      <td>16.229967</td>\n      <td>322893.280814</td>\n      <td>133420.546814</td>\n      <td>32036.174350</td>\n      <td>2004.299894</td>\n      <td>799.638865</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.234959e+09</td>\n      <td>5.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4846.250000</td>\n      <td>3.430417e+09</td>\n      <td>18.000000</td>\n      <td>4942.500000</td>\n      <td>810.750000</td>\n      <td>115.000000</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9691.500000</td>\n      <td>5.618664e+09</td>\n      <td>32.000000</td>\n      <td>9954.500000</td>\n      <td>3403.500000</td>\n      <td>717.000000</td>\n      <td>46.000000</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>14536.750000</td>\n      <td>7.843960e+09</td>\n      <td>47.000000</td>\n      <td>504327.000000</td>\n      <td>125020.000000</td>\n      <td>18222.000000</td>\n      <td>1156.250000</td>\n      <td>292.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>19382.000000</td>\n      <td>9.999873e+09</td>\n      <td>60.000000</td>\n      <td>999817.000000</td>\n      <td>657830.000000</td>\n      <td>256130.000000</td>\n      <td>14994.000000</td>\n      <td>9599.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic EDA - stats\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19382 entries, 0 to 19381\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   #                         19382 non-null  int64  \n",
      " 1   claim_status              19084 non-null  object \n",
      " 2   video_id                  19382 non-null  int64  \n",
      " 3   video_duration_sec        19382 non-null  int64  \n",
      " 4   video_transcription_text  19084 non-null  object \n",
      " 5   verified_status           19382 non-null  object \n",
      " 6   author_ban_status         19382 non-null  object \n",
      " 7   video_view_count          19084 non-null  float64\n",
      " 8   video_like_count          19084 non-null  float64\n",
      " 9   video_share_count         19084 non-null  float64\n",
      " 10  video_download_count      19084 non-null  float64\n",
      " 11  video_comment_count       19084 non-null  float64\n",
      "dtypes: float64(5), int64(3), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Basic EDA - Columns\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Missing Value Imputation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for each column:\n",
      "#                             0\n",
      "claim_status                298\n",
      "video_id                      0\n",
      "video_duration_sec            0\n",
      "video_transcription_text    298\n",
      "verified_status               0\n",
      "author_ban_status             0\n",
      "video_view_count            298\n",
      "video_like_count            298\n",
      "video_share_count           298\n",
      "video_download_count        298\n",
      "video_comment_count         298\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing Value Detection\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values for each column:\")\n",
    "print(missing_values)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for each column:\n",
      "#                           0\n",
      "claim_status                0\n",
      "video_id                    0\n",
      "video_duration_sec          0\n",
      "video_transcription_text    0\n",
      "verified_status             0\n",
      "author_ban_status           0\n",
      "video_view_count            0\n",
      "video_like_count            0\n",
      "video_share_count           0\n",
      "video_download_count        0\n",
      "video_comment_count         0\n",
      "dtype: int64\n",
      "(19084, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": "           # claim_status    video_id  video_duration_sec  \\\n19079  19080      opinion  1492320297                  49   \n19080  19081      opinion  9841347807                  23   \n19081  19082      opinion  8024379946                  50   \n19082  19083      opinion  7425795014                   8   \n19083  19084      opinion  4094655375                  58   \n\n                                                               video_transcription_text  \\\n19079                 in our opinion the earth holds about 11 quintillion pounds of air   \n19080                in our opinion the queens in ant colonies live for around 30 years   \n19081                             in our opinion the moon is moving away from the earth   \n19082  in our opinion lightning strikes somewhere on earth about 100 times every second   \n19083            in our opinion a pineapple plant can only produce one pineapple a year   \n\n      verified_status author_ban_status  video_view_count  video_like_count  \\\n19079    not verified            active            6067.0             423.0   \n19080    not verified            active            2973.0             820.0   \n19081    not verified            active             734.0             102.0   \n19082    not verified            active            3394.0             655.0   \n19083    not verified            active            5034.0             815.0   \n\n       video_share_count  video_download_count  video_comment_count  \n19079               81.0                   8.0                  2.0  \n19080               70.0                   3.0                  0.0  \n19081                7.0                   2.0                  1.0  \n19082              123.0                  11.0                  4.0  \n19083              281.0                  11.0                  1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>claim_status</th>\n      <th>video_id</th>\n      <th>video_duration_sec</th>\n      <th>video_transcription_text</th>\n      <th>verified_status</th>\n      <th>author_ban_status</th>\n      <th>video_view_count</th>\n      <th>video_like_count</th>\n      <th>video_share_count</th>\n      <th>video_download_count</th>\n      <th>video_comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19079</th>\n      <td>19080</td>\n      <td>opinion</td>\n      <td>1492320297</td>\n      <td>49</td>\n      <td>in our opinion the earth holds about 11 quintillion pounds of air</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>6067.0</td>\n      <td>423.0</td>\n      <td>81.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>19080</th>\n      <td>19081</td>\n      <td>opinion</td>\n      <td>9841347807</td>\n      <td>23</td>\n      <td>in our opinion the queens in ant colonies live for around 30 years</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>2973.0</td>\n      <td>820.0</td>\n      <td>70.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19081</th>\n      <td>19082</td>\n      <td>opinion</td>\n      <td>8024379946</td>\n      <td>50</td>\n      <td>in our opinion the moon is moving away from the earth</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>734.0</td>\n      <td>102.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19082</th>\n      <td>19083</td>\n      <td>opinion</td>\n      <td>7425795014</td>\n      <td>8</td>\n      <td>in our opinion lightning strikes somewhere on earth about 100 times every second</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>3394.0</td>\n      <td>655.0</td>\n      <td>123.0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>19083</th>\n      <td>19084</td>\n      <td>opinion</td>\n      <td>4094655375</td>\n      <td>58</td>\n      <td>in our opinion a pineapple plant can only produce one pineapple a year</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>5034.0</td>\n      <td>815.0</td>\n      <td>281.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Value Deletion\n",
    "df = df[:-298]\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values for each column:\")\n",
    "print(missing_values)\n",
    "print(df.shape)\n",
    "df.tail(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Duplicate Value Detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classify Claim/Opinion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preparation / Basic Feature Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Data Set\n",
      "(19084, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  claim_status  video_duration_sec verified_status author_ban_status  \\\n0        claim                  59    not verified      under review   \n1        claim                  32    not verified            active   \n2        claim                  31    not verified            active   \n3        claim                  25    not verified            active   \n4        claim                  19    not verified            active   \n\n   video_view_count  video_like_count  video_share_count  \\\n0          343296.0           19425.0              241.0   \n1          140877.0           77355.0            19034.0   \n2          902185.0           97690.0             2858.0   \n3          437506.0          239954.0            34812.0   \n4           56167.0           34987.0             4110.0   \n\n   video_download_count  video_comment_count  \n0                   1.0                  0.0  \n1                1161.0                684.0  \n2                 833.0                329.0  \n3                1234.0                584.0  \n4                 547.0                152.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>claim_status</th>\n      <th>video_duration_sec</th>\n      <th>verified_status</th>\n      <th>author_ban_status</th>\n      <th>video_view_count</th>\n      <th>video_like_count</th>\n      <th>video_share_count</th>\n      <th>video_download_count</th>\n      <th>video_comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>claim</td>\n      <td>59</td>\n      <td>not verified</td>\n      <td>under review</td>\n      <td>343296.0</td>\n      <td>19425.0</td>\n      <td>241.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>claim</td>\n      <td>32</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>140877.0</td>\n      <td>77355.0</td>\n      <td>19034.0</td>\n      <td>1161.0</td>\n      <td>684.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>claim</td>\n      <td>31</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>902185.0</td>\n      <td>97690.0</td>\n      <td>2858.0</td>\n      <td>833.0</td>\n      <td>329.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>claim</td>\n      <td>25</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>437506.0</td>\n      <td>239954.0</td>\n      <td>34812.0</td>\n      <td>1234.0</td>\n      <td>584.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>claim</td>\n      <td>19</td>\n      <td>not verified</td>\n      <td>active</td>\n      <td>56167.0</td>\n      <td>34987.0</td>\n      <td>4110.0</td>\n      <td>547.0</td>\n      <td>152.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num = df.drop([\"#\", \"video_id\", \"video_transcription_text\"], axis=1)\n",
    "print(\"Numeric Data Set\")\n",
    "print(df_num.shape)\n",
    "df_num.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pair plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [],
   "source": [
    "## Pair Plots\n",
    "palette = {'opinion': '#10BFBF', 'claim': '#EE1D52'}\n",
    "numeric_columns = [col for col in df_num.columns if (df_num[col].nunique() > 2) and (np.issubdtype(df_num[col].dtype, np.number))]\n",
    "sns.pairplot(df_num[numeric_columns + ['claim_status']], hue='claim_status', palette=palette)\n",
    "plt.suptitle('Pairplot of Numeric Features', size=18, fontweight=\"bold\")\n",
    "plt.savefig('chart/pairplot.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'claim_status' unique value: ['claim' 'opinion']\n",
      "Column 'verified_status' unique value: ['not verified' 'verified']\n",
      "Column 'author_ban_status' unique value: ['under review' 'active' 'banned']\n"
     ]
    }
   ],
   "source": [
    "print(\"Column 'claim_status' unique value:\", df_num[\"claim_status\"].unique())\n",
    "print(\"Column 'verified_status' unique value:\", df_num[\"verified_status\"].unique())\n",
    "print(\"Column 'author_ban_status' unique value:\", df_num[\"author_ban_status\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [],
   "source": [
    "# Pie chart for categorical data\n",
    "def plot_pie(ax, column, df):\n",
    "    value_counts = df[column].value_counts()\n",
    "    labels = value_counts.index\n",
    "    sizes = value_counts.values\n",
    "    ax.pie(sizes, labels=labels, autopct='%1.1f%%', textprops={'fontsize': 24}, colors=['#10BFBF', '#EE1D52', '#598B8E'], explode=[0.05]*len(labels))\n",
    "    ax.set_title(f'{column}', fontsize=36)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "plt.title(\"Pie Chart for Categorical Data\")\n",
    "plot_pie(axs[0], 'claim_status', df=df)\n",
    "plot_pie(axs[1], 'verified_status', df=df)\n",
    "plot_pie(axs[2], 'author_ban_status',df=df)\n",
    "plt.tight_layout()\n",
    "plt.savefig('chart/pie_chart.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [],
   "source": [
    "# Pie chart for claim data\n",
    "df_claim = df_num[df_num['claim_status'] == \"claim\"]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "plt.title(\"Pie Chart for Categorical Data\")\n",
    "plot_pie(axs[0], 'claim_status', df=df_claim)\n",
    "plot_pie(axs[1], 'verified_status', df=df_claim)\n",
    "plot_pie(axs[2], 'author_ban_status', df=df_claim)\n",
    "plt.tight_layout()\n",
    "plt.savefig('chart/pie_chart_claim.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [],
   "source": [
    "# Pie chart for opinion data\n",
    "df_opinion = df_num[df_num['claim_status'] == \"opinion\"]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "plt.title(\"Pie Chart for Categorical Data\")\n",
    "plot_pie(axs[0], 'claim_status', df=df_opinion)\n",
    "plot_pie(axs[1], 'verified_status', df=df_opinion)\n",
    "plot_pie(axs[2], 'author_ban_status', df=df_opinion)\n",
    "plt.tight_layout()\n",
    "plt.savefig('chart/pie_chart_opinion.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified_status  not verified  verified\n",
      "claim_status                           \n",
      "claim                    9399       209\n",
      "opinion                  8485       991\n"
     ]
    }
   ],
   "source": [
    "crosstab_verified = pd.crosstab(df['claim_status'], df['verified_status'])\n",
    "print(crosstab_verified)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author_ban_status  active  banned  under review\n",
      "claim_status                                   \n",
      "claim                6566    1439          1603\n",
      "opinion              8817     196           463\n"
     ]
    }
   ],
   "source": [
    "crosstab_verified = pd.crosstab(df['claim_status'], df['author_ban_status'])\n",
    "print(crosstab_verified)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical Data Encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Transfer all categorical columns into numeric\n",
    "## Convert binary categorical columns to 0 and 1\n",
    "df_num['claim_status'] = df_num['claim_status'].map({'opinion': 0, 'claim': 1})\n",
    "df_num['verified_status'] = df_num['verified_status'].map({'not verified': 0, 'verified': 1})\n",
    "\n",
    "## Convert trinary categorical columns to 0 and 1 using one-hot encoder\n",
    "one_hot = pd.get_dummies(df_num['author_ban_status'], prefix='author')\n",
    "df_num = df_num.drop('author_ban_status', axis=1)\n",
    "df_num = pd.concat([df_num, one_hot], axis=1)\n",
    "\n",
    "df_num[['author_active', 'author_banned', 'author_under review']] = df_num[\n",
    "    ['author_active', 'author_banned', 'author_under review']].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame:\n",
      "(19084, 11)\n",
      "   claim_status  video_duration_sec  verified_status  video_view_count  \\\n",
      "0             1                  59                0          343296.0   \n",
      "1             1                  32                0          140877.0   \n",
      "2             1                  31                0          902185.0   \n",
      "3             1                  25                0          437506.0   \n",
      "4             1                  19                0           56167.0   \n",
      "\n",
      "   video_like_count  video_share_count  video_download_count  \\\n",
      "0           19425.0              241.0                   1.0   \n",
      "1           77355.0            19034.0                1161.0   \n",
      "2           97690.0             2858.0                 833.0   \n",
      "3          239954.0            34812.0                1234.0   \n",
      "4           34987.0             4110.0                 547.0   \n",
      "\n",
      "   video_comment_count  author_active  author_banned  author_under review  \n",
      "0                  0.0              0              0                    1  \n",
      "1                684.0              1              0                    0  \n",
      "2                329.0              1              0                    0  \n",
      "3                584.0              1              0                    0  \n",
      "4                152.0              1              0                    0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Updated DataFrame:\")\n",
    "print(df_num.shape)\n",
    "print(df_num.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows where claim_status is 'opinion': 9476 which is 49.65%\n",
      "The number of rows where claim_status is 'claim': 9608 which is 50.35%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number and the percentage of rows\n",
    "count_zeros = sum(df_num['claim_status'] == 0)\n",
    "count_ones = sum(df_num['claim_status'] == 1)\n",
    "print(f\"The number of rows where claim_status is 'opinion': {count_zeros} which is {round(100*count_zeros/df_num.shape[0],2)}%\")\n",
    "print(f\"The number of rows where claim_status is 'claim': {count_ones} which is {round(100*count_ones/df_num.shape[0],2)}%\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows where verified_status is 'not verified': 17884 which is 93.71%\n",
      "The number of rows where verified_status is 'verified': 1200 which is 6.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_zeros = sum(df_num['verified_status'] == 0)\n",
    "count_ones = sum(df_num['verified_status'] == 1)\n",
    "print(f\"The number of rows where verified_status is 'not verified': {count_zeros} which is {round(100*count_zeros/df_num.shape[0],2)}%\")\n",
    "print(f\"The number of rows where verified_status is 'verified': {count_ones} which is {round(100*count_ones/df_num.shape[0],2)}%\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows where author is 'active': 15383 which is 80.61%\n",
      "The number of rows where author is 'banned': 1635 which is 8.57%\n",
      "The number of rows where author is 'under review': 2066 which is 10.83%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_active = sum(df_num['author_active'] == 1)\n",
    "count_banned = sum(df_num['author_banned'] == 1)\n",
    "count_under_review = sum(df_num['author_under review'] == 1)\n",
    "print(f\"The number of rows where author is 'active': {count_active} which is {round(100*count_active/df_num.shape[0],2)}%\")\n",
    "print(f\"The number of rows where author is 'banned': {count_banned} which is {round(100*count_banned/df_num.shape[0],2)}%\")\n",
    "print(f\"The number of rows where author is 'under review': {count_under_review} which is {round(100*count_under_review/df_num.shape[0],2)}%\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [],
   "source": [
    "## Distribution of Each Attribute\n",
    "numeric_columns = [col for col in df_num.columns if (df_num[col].nunique() > 2) and (np.issubdtype(df_num[col].dtype, np.number))]\n",
    "plt.figure(figsize=(20, 10))\n",
    "for index, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(2, 3, index)\n",
    "    plt.hist(df_num[column], bins=40, color=\"#10BFBF\")\n",
    "    plt.title(column)\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('chart/histogram.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x2000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Box Plot part 1\n",
    "numeric_columns = [col for col in df_num.columns if (df_num[col].nunique() > 2) and (np.issubdtype(df_num[col].dtype, np.number))]\n",
    "plt.figure(figsize=(12, 20))\n",
    "plt.title(\"Features Box Plot\")\n",
    "df_num[numeric_columns].plot(kind='box', subplots=True, layout=(2, 3), sharex=False, sharey=False, grid=True, color=\"#10BFBF\", figsize=(20, 10))\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Features Box Plot', size=18, fontweight=\"bold\", y=1.02)\n",
    "plt.savefig('chart/boxplot.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after standardization:\n",
      "   claim_status  video_duration_sec  verified_status  video_view_count  \\\n",
      "0             1            1.637872                0          0.274362   \n",
      "1             1           -0.026119                0         -0.352545   \n",
      "2             1           -0.087748                0          2.005286   \n",
      "3             1           -0.457524                0          0.566138   \n",
      "4             1           -0.827300                0         -0.614899   \n",
      "\n",
      "   video_like_count  video_share_count  video_download_count  \\\n",
      "0         -0.486292          -0.514877             -0.523104   \n",
      "1         -0.052090           0.071757              0.055667   \n",
      "2          0.100327          -0.433186             -0.107985   \n",
      "3          1.166638           0.564275              0.092090   \n",
      "4         -0.369650          -0.394104             -0.250682   \n",
      "\n",
      "   video_comment_count  author_active  author_banned  author_under review  \n",
      "0            -0.436849              0              0                    1  \n",
      "1             0.418560              1              0                    0  \n",
      "2            -0.025402              1              0                    0  \n",
      "3             0.293500              1              0                    0  \n",
      "4            -0.246758              1              0                    0  \n"
     ]
    }
   ],
   "source": [
    "## Standardize the data\n",
    "numeric_columns = [col for col in df_num.columns if (df_num[col].nunique() > 2) and (np.issubdtype(df_num[col].dtype, np.number))]\n",
    "scaler = StandardScaler()\n",
    "df_num.loc[:, numeric_columns] = scaler.fit_transform(df_num[numeric_columns])\n",
    "print(\"DataFrame after standardization:\")\n",
    "print(df_num.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "## Box Plot part 2\n",
    "plt.figure(figsize=(20, 10))\n",
    "df_num[numeric_columns].boxplot()\n",
    "plt.title('Continuous Numerical Features Box Plot after Standardization', size=24, fontweight=\"bold\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"value\", size=18)\n",
    "plt.savefig('chart/boxplots.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [],
   "source": [
    "# KDE for All Features\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 10), sharey=True)\n",
    "axs = axs.flatten()\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    sns.kdeplot(df_num[column], fill=True, ax=axs[i],color=\"#10BFBF\")\n",
    "    axs[i].set_title(f\"PDF of {column}\")\n",
    "    axs[i].set_xlabel(column)\n",
    "    axs[i].set_ylabel(\"Density\")\n",
    "    axs[i].grid(True)\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.savefig('chart/kde.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [],
   "source": [
    "# KDE for All Features in claim label\n",
    "df_claim = df_num[df_num['claim_status'] == 1]\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 10), sharey=True)\n",
    "axs = axs.flatten()\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    sns.kdeplot(data=df_claim, x=column, label='claim', fill=True, color=\"#EE1D52\", ax=axs[i])\n",
    "    axs[i].set_title(f\"PDF of {column}\")\n",
    "    axs[i].set_xlabel(column)\n",
    "    axs[i].set_ylabel(\"Density\")\n",
    "    axs[i].grid(True)\n",
    "    axs[i].legend()\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.savefig('chart/kde_claim.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [],
   "source": [
    "# KDE for All Features in opinion label\n",
    "df_opinion = df_num[df_num['claim_status'] == 0]\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 10), sharey=True)\n",
    "axs = axs.flatten()\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    sns.kdeplot(data=df_opinion, x=column, label='opinion', fill=True, color=\"#598B8E\", ax=axs[i])\n",
    "    axs[i].set_title(f\"PDF of {column}\")\n",
    "    axs[i].set_xlabel(column)\n",
    "    axs[i].set_ylabel(\"Density\")\n",
    "    axs[i].grid(True)\n",
    "    axs[i].legend()\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.savefig('chart/kde_opinion.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_status            1.000000\n",
      "video_view_count        0.768170\n",
      "video_like_count        0.619399\n",
      "video_download_count    0.513217\n",
      "video_share_count       0.512067\n",
      "video_comment_count     0.430487\n",
      "author_banned           0.230605\n",
      "author_under review     0.189853\n",
      "video_duration_sec      0.003914\n",
      "verified_status        -0.170600\n",
      "author_active          -0.312438\n",
      "Name: claim_status, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Correlation\n",
    "plt.figure(figsize=(18, 14))\n",
    "sns.heatmap(df_num.corr(), annot=False, linewidths=0.03, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap', size=18, fontweight=\"bold\")\n",
    "plt.savefig('chart/heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "corr_matrix = df_num.corr()\n",
    "print(corr_matrix['claim_status'].sort_values(ascending=False))\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modeling Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### One Split Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "(15267, 10)"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "results = []\n",
    "X = df_num.drop(['claim_status'], axis=1)\n",
    "y = df_num['claim_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "Best hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best score: 0.9953495021698091\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [2, 4, 8, 16]\n",
    "}\n",
    "# Best Record\n",
    "param_grid = { 'n_estimators': [200], 'max_depth': [None], 'min_samples_split': [2], 'min_samples_leaf': [2]}\n",
    "\n",
    "grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(f\"Best hyperparameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "results.append(('Random Forest', grid.best_params_, grid.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "video_duration_sec: 0.0015\n",
      "verified_status: 0.0001\n",
      "video_view_count: 0.3892\n",
      "video_like_count: 0.2156\n",
      "video_share_count: 0.1739\n",
      "video_download_count: 0.1330\n",
      "video_comment_count: 0.0786\n",
      "author_active: 0.0066\n",
      "author_banned: 0.0012\n",
      "author_under review: 0.0003\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid.best_estimator_\n",
    "importances = best_rf.feature_importances_\n",
    "feature_names = X_train.columns.tolist()\n",
    "print(\"Feature Importance:\")\n",
    "for name, importance in zip(feature_names, importances):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "indices = range(len(importances))\n",
    "plt.figure(figsize=(10, 8))  # Set a larger figure size\n",
    "plt.title(\"Feature Importance\")\n",
    "bars = plt.bar(indices, importances, color=\"r\", align=\"center\")\n",
    "plt.xticks(indices, feature_names, rotation=90)\n",
    "plt.xlim([-1, len(importances)])\n",
    "\n",
    "# Place the text above the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, round(yval, 4), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout(pad=1.0)  # Adjust the padding\n",
    "plt.savefig(\"chart/feature_importance.png\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.05, 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best score: 0.9954805208399696\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting\")\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.005, 0.01, 0.05],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 4, 8]\n",
    "}\n",
    "# Second Record\n",
    "param_grid = {'n_estimators': [100], 'learning_rate':  [0.01], 'min_samples_split': [2], 'min_samples_leaf': [8]}\n",
    "# Best Record\n",
    "param_grid = {'n_estimators': [200], 'learning_rate':  [0.05], 'min_samples_split': [2], 'min_samples_leaf': [8]}\n",
    "grid = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42),\n",
    "                       param_grid=param_grid,\n",
    "                       cv=5,\n",
    "                       verbose=2,\n",
    "                       n_jobs=-1)  # n_jobs=-1 will use all available CPU cores\n",
    "grid.fit(X_train, y_train)\n",
    "best_gb = grid.best_estimator_\n",
    "print(f\"Best hyperparameters: {grid.best_params_}\")\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "results.append(('Gradient Boosting', grid.best_params_, grid.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "Best score: 0.9852624588394809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Nearest Neighbors\")\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2] # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "# Best Record\n",
    "param_grid_knn = { 'n_neighbors': [3], 'weights': ['uniform' ], 'p': [2]}\n",
    "\n",
    "grid_knn = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                        param_grid=param_grid_knn,\n",
    "                        cv=5,\n",
    "                        verbose=2,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "grid_knn.fit(X_train, y_train)\n",
    "best_knn = grid_knn.best_estimator_\n",
    "print(f\"Best hyperparameters: {grid_knn.best_params_}\")\n",
    "print(f\"Best score: {grid_knn.best_score_}\")\n",
    "results.append(('K-Nearest Neighbors', grid_knn.best_params_, grid_knn.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linear Discriminant Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis\n",
      "Train score: 0.8814436366018209\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "print(\"Linear Discriminant Analysis\")\n",
    "best_lda = LinearDiscriminantAnalysis()\n",
    "best_lda.fit(X_train, y_train)\n",
    "lda_train_score = best_lda.score(X_train, y_train)\n",
    "print(f\"Train score: {lda_train_score}\")\n",
    "results.append(('Linear Discriminant Analysis', 'N/A', lda_train_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 100, 'solver': 'newton-cg'}\n",
      "Best score: 0.9914849662082086\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "print(\"Logistic Regression\")\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "# Best Record\n",
    "param_grid_lr = {'C': [100], 'solver': ['newton-cg']}\n",
    "grid_lr = GridSearchCV(estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "                       param_grid=param_grid_lr,\n",
    "                       cv=5,\n",
    "                       verbose=2,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "print(f\"Best hyperparameters: {grid_lr.best_params_}\")\n",
    "print(f\"Best score: {grid_lr.best_score_}\")\n",
    "results.append(('Logistic Regression', grid_lr.best_params_, grid_lr.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best score: 0.9950220198454245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/jeffreyhuang/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree\")\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 10]\n",
    "}\n",
    "# Best Record\n",
    "param_grid_dt = {'max_depth': [10], 'min_samples_split': [2],'min_samples_leaf': [1]}\n",
    "grid_dt = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
    "                       param_grid=param_grid_dt,\n",
    "                       cv=5,\n",
    "                       verbose=2,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "best_dt = grid_dt.best_estimator_\n",
    "print(f\"Best hyperparameters: {grid_dt.best_params_}\")\n",
    "print(f\"Best score: {grid_dt.best_score_}\")\n",
    "results.append(('Decision Tree', grid_dt.best_params_, grid_dt.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modeling Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy Train  Accuracy Test  Precision  Recall  \\\n",
      "0        Random Forest          0.9960         0.9953     1.0000  0.9907   \n",
      "1    Gradient Boosting          0.9963         0.9955     0.9995  0.9917   \n",
      "2  K-Nearest Neighbors          0.9891         0.9882     0.9995  0.9772   \n",
      "3                  LDA          0.8814         0.8866     1.0000  0.7754   \n",
      "4  Logistic Regression          0.9916         0.9927     1.0000  0.9855   \n",
      "5        Decision Tree          0.9967         0.9935     0.9958  0.9912   \n",
      "\n",
      "   F1 Score     AUC  \n",
      "0    0.9953  0.9982  \n",
      "1    0.9956  0.9984  \n",
      "2    0.9882  0.9914  \n",
      "3    0.8735  0.9880  \n",
      "4    0.9927  0.9975  \n",
      "5    0.9935  0.9930  \n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy Train', 'Accuracy Test', 'Precision', 'Recall', 'F1 Score', 'AUC'])\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on training set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "    # Predictions on testing set\n",
    "    test_predictions = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "    # Calculating other evaluation metrics on test set\n",
    "    precision = precision_score(y_test, test_predictions)\n",
    "    recall = recall_score(y_test, test_predictions)\n",
    "    f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "    # Probabilities and ROC-AUC for test set only\n",
    "    probabilities = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Record the results\n",
    "    results_df.loc[len(results_df)] = [model_name, round(acc_train, 4), round(acc_test, 4), round(precision, 4), round(recall, 4), round(f1, 4), round(roc_auc, 4)]\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"chart/\"+model_name)\n",
    "    plt.close()\n",
    "\n",
    "# Evaluate each model\n",
    "evaluate_model(best_rf, X_train, y_train, X_test, y_test, \"Random Forest\")\n",
    "evaluate_model(best_gb, X_train, y_train, X_test, y_test, \"Gradient Boosting\")\n",
    "evaluate_model(best_knn, X_train, y_train, X_test, y_test, \"K-Nearest Neighbors\")\n",
    "evaluate_model(best_lda, X_train, y_train, X_test, y_test, \"LDA\")\n",
    "evaluate_model(best_lr, X_train, y_train, X_test, y_test, \"Logistic Regression\")\n",
    "evaluate_model(best_dt, X_train, y_train, X_test, y_test, \"Decision Tree\")\n",
    "\n",
    "# Display final results DataFrame\n",
    "print(results_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy Train  Accuracy Test  Precision  Recall  \\\n",
      "0        Random Forest          0.9960         0.9953     1.0000  0.9907   \n",
      "1    Gradient Boosting          0.9963         0.9955     0.9995  0.9917   \n",
      "2  K-Nearest Neighbors          0.9891         0.9882     0.9995  0.9772   \n",
      "3                  LDA          0.8814         0.8866     1.0000  0.7754   \n",
      "4  Logistic Regression          0.9916         0.9927     1.0000  0.9855   \n",
      "5        Decision Tree          0.9967         0.9935     0.9958  0.9912   \n",
      "\n",
      "   F1 Score     AUC  \n",
      "0    0.9953  0.9982  \n",
      "1    0.9956  0.9984  \n",
      "2    0.9882  0.9914  \n",
      "3    0.8735  0.9880  \n",
      "4    0.9927  0.9975  \n",
      "5    0.9935  0.9930  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Random Forest', {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, 0.9953495021698091), ('Gradient Boosting', {'learning_rate': 0.05, 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 200}, 0.9954805208399696), ('K-Nearest Neighbors', {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}, 0.9852624588394809), ('Linear Discriminant Analysis', 'N/A', 0.8814436366018209), ('Logistic Regression', {'C': 100, 'solver': 'newton-cg'}, 0.9914849662082086), ('Decision Tree', {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}, 0.9950220198454245)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for column in ['Accuracy Train', 'Accuracy Test']:\n",
    "    plt.plot(results_df['Model'], results_df[column], marker='o', label=column)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Model Performance\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"chart/result.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering of Videos Based on Engagement Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19084, 5)\n",
      "   video_view_count  video_like_count  video_share_count  \\\n",
      "0          0.274362         -0.486292          -0.514877   \n",
      "1         -0.352545         -0.052090           0.071757   \n",
      "2          2.005286          0.100327          -0.433186   \n",
      "3          0.566138          1.166638           0.564275   \n",
      "4         -0.614899         -0.369650          -0.394104   \n",
      "\n",
      "   video_download_count  video_comment_count  \n",
      "0             -0.523104            -0.436849  \n",
      "1              0.055667             0.418560  \n",
      "2             -0.107985            -0.025402  \n",
      "3              0.092090             0.293500  \n",
      "4             -0.250682            -0.246758  \n"
     ]
    }
   ],
   "source": [
    "df_eng = df_num[['video_view_count', 'video_like_count', 'video_share_count', 'video_download_count', 'video_comment_count']]\n",
    "print(df_eng.shape)\n",
    "print(df_eng.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def custom_kmeans(data, num_clusters, distance='euclidean'):\n",
    "    # Custom K-means to support different distance metrics\n",
    "    centroids, _ = kmeans(data, num_clusters)\n",
    "    if distance == 'manhattan':\n",
    "        D = cdist(data, centroids, 'cityblock')\n",
    "    else:  # default to euclidean\n",
    "        D = cdist(data, centroids, 'euclidean')\n",
    "    return np.sum(np.min(D, axis=1))\n",
    "\n",
    "wcss_euclidean = []\n",
    "wcss_manhattan = []\n",
    "times_euclidean = []\n",
    "times_manhattan = []\n",
    "\n",
    "for i in range(1, 11):  # Testing for 1 to 10 clusters\n",
    "    # Euclidean distance\n",
    "    start_time = time.time()\n",
    "    wcss_euclidean.append(custom_kmeans(df_eng, i))\n",
    "    times_euclidean.append(time.time() - start_time)\n",
    "\n",
    "    # Manhattan distance\n",
    "    start_time = time.time()\n",
    "    wcss_manhattan.append(custom_kmeans(df_eng, i, 'manhattan'))\n",
    "    times_manhattan.append(time.time() - start_time)\n",
    "\n",
    "# Plotting WCSS for Euclidean and Manhattan distances\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 11), wcss_euclidean, label='Euclidean')\n",
    "plt.plot(range(1, 11), wcss_manhattan, label='Manhattan')\n",
    "plt.title('Elbow Method with Different Distance Metrics')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.legend()\n",
    "plt.savefig(\"chart/wcss.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plotting computational time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 11), times_euclidean, label='Euclidean Time')\n",
    "plt.plot(range(1, 11), times_manhattan, label='Manhattan Time')\n",
    "plt.title('Computational Time with Different Distance Metrics')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.legend()\n",
    "plt.savefig(\"chart/time.png\")\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers:\n",
      "    video_view_count  video_like_count  video_share_count  \\\n",
      "0         -0.709496         -0.588670          -0.489082   \n",
      "1          0.847649          0.256155           0.127238   \n",
      "2          1.497532          1.947156           1.752613   \n",
      "\n",
      "   video_download_count  video_comment_count       sum  \n",
      "0             -0.491100            -0.412453 -2.690801  \n",
      "1              0.071760             0.012175  1.314977  \n",
      "2              1.848101             1.627928  8.673331  \n"
     ]
    }
   ],
   "source": [
    "# Determining the best K (using Euclidean for this example, adjust as needed)\n",
    "best_k = 3 # set this based on the elbow plot\n",
    "centroids, _ = kmeans(df_eng, best_k)\n",
    "df_centroids = pd.DataFrame(centroids, columns=df_eng.columns)\n",
    "df_centroids['sum'] = df_centroids.sum(axis=1)\n",
    "df_centroids_sorted = df_centroids.sort_values(by='sum')\n",
    "print(\"Cluster centers:\\n\", df_centroids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   # claim_status    video_id  video_duration_sec  \\\n",
      "0  1        claim  7017666017                  59   \n",
      "1  2        claim  4014381136                  32   \n",
      "2  3        claim  9859838091                  31   \n",
      "3  4        claim  1866847991                  25   \n",
      "4  5        claim  7105231098                  19   \n",
      "\n",
      "                                                                                                                    video_transcription_text  \\\n",
      "0                                          someone shared with me that drone deliveries are already happening and will become common by 2025   \n",
      "1                                someone shared with me that there are more microorganisms in one teaspoon of soil than people on the planet   \n",
      "2  someone shared with me that american industrialist andrew carnegie had a net worth of $475 million usd, worth over $300 billion usd today   \n",
      "3        someone shared with me that the metro of st. petersburg, with an average depth of hundred meters, is the deepest metro in the world   \n",
      "4           someone shared with me that the number of businesses allowing employees to bring pets to the workplace has grown by 6% worldwide   \n",
      "\n",
      "  verified_status author_ban_status  video_view_count  video_like_count  \\\n",
      "0    not verified      under review          343296.0           19425.0   \n",
      "1    not verified            active          140877.0           77355.0   \n",
      "2    not verified            active          902185.0           97690.0   \n",
      "3    not verified            active          437506.0          239954.0   \n",
      "4    not verified            active           56167.0           34987.0   \n",
      "\n",
      "   video_share_count  video_download_count  video_comment_count  cluster  \n",
      "0              241.0                   1.0                  0.0        0  \n",
      "1            19034.0                1161.0                684.0        1  \n",
      "2             2858.0                 833.0                329.0        1  \n",
      "3            34812.0                1234.0                584.0        1  \n",
      "4             4110.0                 547.0                152.0        0  \n"
     ]
    }
   ],
   "source": [
    "df['cluster'] = vq(df_eng, centroids)[0]\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "cluster_names = {0: 'Cluster 0', 1: 'Cluster 1', 2: 'Cluster 2'}\n",
    "df['cluster'] = df['cluster'].map(cluster_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "palette = {'Cluster 0': '#10BFBF', 'Cluster 1': '#FFD700', 'Cluster 2': '#EE1D52'} # Example colors\n",
    "sns.pairplot(df[['video_view_count', 'video_like_count', 'video_share_count', 'video_download_count', 'video_comment_count', 'cluster']], hue='cluster', palette=palette)\n",
    "plt.suptitle('Pairplot of Numeric Features by Cluster', size=18, fontweight=\"bold\")\n",
    "plt.savefig('chart/pairplot_cluster.png')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shareability Factors of Video Content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prepare Data Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data Set\n",
      "(19084, 5)\n",
      "  claim_status verified_status author_ban_status  \\\n",
      "0        claim    not verified      under review   \n",
      "1        claim    not verified            active   \n",
      "2        claim    not verified            active   \n",
      "3        claim    not verified            active   \n",
      "4        claim    not verified            active   \n",
      "\n",
      "                                                                                                                    video_transcription_text  \\\n",
      "0                                          someone shared with me that drone deliveries are already happening and will become common by 2025   \n",
      "1                                someone shared with me that there are more microorganisms in one teaspoon of soil than people on the planet   \n",
      "2  someone shared with me that american industrialist andrew carnegie had a net worth of $475 million usd, worth over $300 billion usd today   \n",
      "3        someone shared with me that the metro of st. petersburg, with an average depth of hundred meters, is the deepest metro in the world   \n",
      "4           someone shared with me that the number of businesses allowing employees to bring pets to the workplace has grown by 6% worldwide   \n",
      "\n",
      "   video_share_count  \n",
      "0              241.0  \n",
      "1            19034.0  \n",
      "2             2858.0  \n",
      "3            34812.0  \n",
      "4             4110.0  \n"
     ]
    }
   ],
   "source": [
    "# Basic feature selection\n",
    "df_text = df[['claim_status', 'verified_status', 'author_ban_status', \"video_transcription_text\", 'video_share_count']]\n",
    "print(\"Text Data Set\")\n",
    "print(df_text.shape)\n",
    "print(df_text.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Pre-processing(Data Cleaning/Tokenization/Stopword Removal/Lemmatization and Stemming/POS Filtering)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  claim_status verified_status author_ban_status  video_share_count  \\\n",
      "0        claim    not verified      under review              241.0   \n",
      "1        claim    not verified            active            19034.0   \n",
      "2        claim    not verified            active             2858.0   \n",
      "3        claim    not verified            active            34812.0   \n",
      "4        claim    not verified            active             4110.0   \n",
      "5        claim    not verified      under review            62303.0   \n",
      "6        claim    not verified            active           193911.0   \n",
      "7        claim    not verified            active               50.0   \n",
      "8        claim    not verified            active             1050.0   \n",
      "9        claim        verified            active            67739.0   \n",
      "\n",
      "                                  processed_text  \n",
      "0                          drone delivery become  \n",
      "1             microorganism teaspoon soil planet  \n",
      "2                        industrialist usd today  \n",
      "3                metro st petersburg depth metro  \n",
      "4          business employee workplace worldwide  \n",
      "5  product gdp indicator country trade potential  \n",
      "6   elvis presley sell record music band beatles  \n",
      "7                               christmas crosby  \n",
      "8        half world population access web device  \n",
      "9                        drive store work create  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/n0t4d3wj2gqbrxnnrjv718mm0000gn/T/ipykernel_24846/1405724467.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['processed_text'] = df_text[\"video_transcription_text\"].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    custom_stopwords = ['someone','shared', 'claim', 'read', 'first', 'learned', 'people', 'media', 'colleague', 'friend', 'discovered', 'friends', 'colleagues', 'family', 'actually', 'news', 'average', 'every', 'never', 'total', 'gets', 'one', \"world\", \"day\", \"time\", \"used\", \"around\", \"earth\", \"number\", \"year\", \"largest\", \"single\", \"ever\", \"known\", \"without\", \"always\", \"worth\", \"take\", \"thing\", \"somewhere\", \"side\", \"get\", \"use\", \"row\", \"away\", \"hypothesis\", \"opinion\"]\n",
    "    stop_words.update(custom_stopwords)\n",
    "    tokens = [word for word in tokens if word not in stop_words and not word.isdigit()]\n",
    "\n",
    "    # Lemmatization with POS tagging\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_output = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n",
    "\n",
    "    # Keep only nouns\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(lemmatized_output) if pos.startswith('N')]\n",
    "\n",
    "    return \" \".join(nouns)\n",
    "\n",
    "df_text['processed_text'] = df_text[\"video_transcription_text\"].apply(preprocess_text)\n",
    "df_text = df_text.drop(['video_transcription_text'], axis=1)\n",
    "print(df_text.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Word Cloud Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [
    "def generate_word_clouds(word_groups, save_path='word_clouds.png', width=600, height=450):\n",
    "    \"\"\"\n",
    "    Generate and save a word cloud image for multiple groups of words.\n",
    "\n",
    "    Parameters:\n",
    "    - word_groups: A dictionary with titles and corresponding text for each word cloud.\n",
    "    - save_path: The path where the image will be saved.\n",
    "    - width: The width of each word cloud.\n",
    "    - height: The height of each word cloud.\n",
    "    \"\"\"\n",
    "    num_word_clouds = len(word_groups)\n",
    "    fig, axes = plt.subplots(1, num_word_clouds, figsize=(5 * num_word_clouds, 4))\n",
    "\n",
    "    if num_word_clouds == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for (title, text), ax in zip(word_groups.items(), axes):\n",
    "        wordcloud = WordCloud(width=width, height=height, background_color='white').generate(text)\n",
    "        ax.imshow(wordcloud, interpolation='nearest')\n",
    "        ax.set_title(title, weight='bold')\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [],
   "source": [
    "word_groups = {\n",
    "    \"Opinion Shorts\": \" \".join(df_text[df_text.claim_status == 'opinion'].processed_text),\n",
    "    \"Claim Shorts\": \" \".join(df_text[df_text.claim_status == 'claim'].processed_text)\n",
    "}\n",
    "generate_word_clouds(word_groups, save_path=\"chart/word_cloud_claim.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [],
   "source": [
    "word_groups = {\n",
    "    \"Verified Author's Videos\": \" \".join(df_text[df_text.verified_status == 'verified'].processed_text),\n",
    "    \"Non-verified Author's Videos\": \" \".join(df_text[df_text.verified_status == 'not verified'].processed_text)\n",
    "}\n",
    "generate_word_clouds(word_groups, save_path=\"chart/word_cloud_verified.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [],
   "source": [
    "word_groups = {\n",
    "    \"Active Author's Videos\": \" \".join(df_text[df_text.author_ban_status == 'active'].processed_text),\n",
    "    \"Under Review Author's Videos\": \" \".join(df_text[df_text.author_ban_status == 'under review'].processed_text),\n",
    "    \"Banned Author's Videos\": \" \".join(df_text[df_text.author_ban_status == 'banned'].processed_text)\n",
    "}\n",
    "generate_word_clouds(word_groups, save_path=\"chart/word_cloud_ban.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19084, 2)\n",
      "    video_share_count                                 processed_text\n",
      "0               241.0                          drone delivery become\n",
      "1             19034.0             microorganism teaspoon soil planet\n",
      "2              2858.0                        industrialist usd today\n",
      "3             34812.0                metro st petersburg depth metro\n",
      "4              4110.0          business employee workplace worldwide\n",
      "5             62303.0  product gdp indicator country trade potential\n",
      "6            193911.0   elvis presley sell record music band beatles\n",
      "7                50.0                               christmas crosby\n",
      "8              1050.0        half world population access web device\n",
      "9             67739.0                        drive store work create\n",
      "10            23062.0                                spends internet\n",
      "11            19474.0                            generates byte data\n",
      "12            97995.0                       record cricket match day\n",
      "13           154917.0                          event summer olympics\n",
      "14            81496.0        basketball legend wilt chamberlain game\n",
      "15               29.0             city bus network jakarta indonesia\n",
      "16            17710.0                                      dog sense\n",
      "17             2804.0                             garden snail teeth\n",
      "18            37929.0                                           moon\n",
      "19             2240.0                                      moon part\n"
     ]
    }
   ],
   "source": [
    "# Remove features\n",
    "df_text = df_text.drop(['claim_status', 'verified_status', 'author_ban_status'], axis=1)\n",
    "print(df_text.shape)\n",
    "print(df_text.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   sentiments  video_share_count\n",
      "sentiments           1.000000          -0.044933\n",
      "video_share_count   -0.044933           1.000000\n",
      "sentiment_class\n",
      "neutral     16161\n",
      "positive     2432\n",
      "negative      491\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis with VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df_text['sentiments'] = df_text['processed_text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "#df_text['sentiment_class'] = df_text['sentiments'].apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral'))\n",
    "#print(df_text.head(10))\n",
    "print(df_text[['sentiments', 'video_share_count']].corr())\n",
    "df_text['sentiment_class'] = df_text['sentiments'].apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral'))\n",
    "sentiment_counts = df_text['sentiment_class'].value_counts()\n",
    "print(sentiment_counts)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, colors=['#10BFBF', '#EE1D52', '#598B8E'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.savefig(\"chart/sentiments_pie.png\")\n",
    "plt.close()\n",
    "df_text = df_text.drop(['sentiments', 'sentiment_class'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Topic Clustering with Latent Dirichlet Allocation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "data": {
      "text/plain": "LatentDirichletAllocation(learning_decay=0.8, max_iter=20, n_components=100,\n                          random_state=321)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_decay=0.8, max_iter=20, n_components=100,\n                          random_state=321)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_decay=0.8, max_iter=20, n_components=100,\n                          random_state=321)</pre></div></div></div></div></div>"
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_data_vectorized = tfidf_vectorizer.fit_transform(df_text['processed_text'])\n",
    "\n",
    "# Fitting LDA model\n",
    "lda_tfidf = LatentDirichletAllocation(n_components=100, learning_decay=0.8, max_iter=20, random_state=321)\n",
    "lda_tfidf.fit(tfidf_data_vectorized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "entrepreneur denmark emirate ireland towards\n",
      "Topic 1:\n",
      "egg surface prevent break area\n",
      "Topic 2:\n",
      "move flea moon size baby\n",
      "Topic 3:\n",
      "raven speak spiderlings call spider\n",
      "Topic 4:\n",
      "banana flavor length mar cat\n",
      "Topic 5:\n",
      "fear dont sneeze sleep fall\n",
      "Topic 6:\n",
      "part contains pluto life moon\n",
      "Topic 7:\n",
      "expansion freight day ship eat\n",
      "Topic 8:\n",
      "antler reindeer organ acid metal\n",
      "Topic 9:\n",
      "person record operate goat rectangular\n",
      "Topic 10:\n",
      "driver traffic bathwater duration life\n",
      "Topic 11:\n",
      "horsehair bow christmas crosby violin\n",
      "Topic 12:\n",
      "saliva taste food cant sail\n",
      "Topic 13:\n",
      "record tennis match hour george\n",
      "Topic 14:\n",
      "parrot foot butterfly taste baseball\n",
      "Topic 15:\n",
      "dubai create ward dance mosquito\n",
      "Topic 16:\n",
      "radio instrument china invention harmonica\n",
      "Topic 17:\n",
      "language country island adulthood bone\n",
      "Topic 18:\n",
      "phone time strike championship india\n",
      "Topic 19:\n",
      "eye wont sneeze wind brain\n",
      "Topic 20:\n",
      "system planet solar venus dwarf\n",
      "Topic 21:\n",
      "eiffel tower job invent taller\n",
      "Topic 22:\n",
      "water saturn mammal locate acre\n",
      "Topic 23:\n",
      "keyboard standard noise state alaska\n",
      "Topic 24:\n",
      "shell bulletproof pumpkin store work\n",
      "Topic 25:\n",
      "flamingo ankle leg transport train\n",
      "Topic 26:\n",
      "living tree badminton household zealander\n",
      "Topic 27:\n",
      "expiration address date email water\n",
      "Topic 28:\n",
      "desert sahara sandy lollipop center\n",
      "Topic 29:\n",
      "snake earthquake metro predict decrease\n",
      "Topic 30:\n",
      "mount vehicle employ industry create\n",
      "Topic 31:\n",
      "animal cheetah emotion expression prompt\n",
      "Topic 32:\n",
      "ounce hair weight strand elvis\n",
      "Topic 33:\n",
      "grass specie elasticity rubber operating\n",
      "Topic 34:\n",
      "teaspoon microorganism soil planet tell\n",
      "Topic 35:\n",
      "lift body belongs squid pair\n",
      "Topic 36:\n",
      "heartbeat connectivity mile roam india\n",
      "Topic 37:\n",
      "type user bird stop dog\n",
      "Topic 38:\n",
      "discussion board game legend chamberlain\n",
      "Topic 39:\n",
      "survive song otter swim amazon\n",
      "Topic 40:\n",
      "sense product rubiks dog cube\n",
      "Topic 41:\n",
      "state increase pineapple airport reptile\n",
      "Topic 42:\n",
      "luck japan dark glow shark\n",
      "Topic 43:\n",
      "business sale worldwide men woman\n",
      "Topic 44:\n",
      "pyramid world flame gravity ft\n",
      "Topic 45:\n",
      "moon attract see impression set\n",
      "Topic 46:\n",
      "car mileage mile convince reason\n",
      "Topic 47:\n",
      "claim article study mention jetpacks\n",
      "Topic 48:\n",
      "champion winner english location science\n",
      "Topic 49:\n",
      "canada lead south direction dragonfly\n",
      "Topic 50:\n",
      "month think thailand mouse sport\n",
      "Topic 51:\n",
      "element table family report mention\n",
      "Topic 52:\n",
      "tongue print stick parent crocodile\n",
      "Topic 53:\n",
      "color season computer code reindeer\n",
      "Topic 54:\n",
      "hour history flight koala brazil\n",
      "Topic 55:\n",
      "name pinecone subway girl world\n",
      "Topic 56:\n",
      "heart beat stomach dream face\n",
      "Topic 57:\n",
      "live space honk diamond horn\n",
      "Topic 58:\n",
      "star dice sky side heard\n",
      "Topic 59:\n",
      "jupiter diamond moon saturn rain\n",
      "Topic 60:\n",
      "teeth alike telescope garden situation\n",
      "Topic 61:\n",
      "online fingerless flight flea flavor\n",
      "Topic 62:\n",
      "city damascus network indonesia jakarta\n",
      "Topic 63:\n",
      "spends item tuesday week day\n",
      "Topic 64:\n",
      "child phrase meaning orchestra africa\n",
      "Topic 65:\n",
      "apple snowflake inch cyanide seed\n",
      "Topic 66:\n",
      "memory floss erwin physicist schrdinger\n",
      "Topic 67:\n",
      "boar everyday form check wash\n",
      "Topic 68:\n",
      "neptune heat meow adult sun\n",
      "Topic 69:\n",
      "zone rainbow fruit seed strawberry\n",
      "Topic 70:\n",
      "philippine age change island size\n",
      "Topic 71:\n",
      "fission electricity shot cannonball event\n",
      "Topic 72:\n",
      "wallpaper wrap jump air foot\n",
      "Topic 73:\n",
      "australia rock crater moon lake\n",
      "Topic 74:\n",
      "fly bird redwood tree backwards\n",
      "Topic 75:\n",
      "plant grow hand fingernail centimeter\n",
      "Topic 76:\n",
      "dog piece predator construct violin\n",
      "Topic 77:\n",
      "restaurant believe rate plate fingernail\n",
      "Topic 78:\n",
      "venus mercury hook cactus spine\n",
      "Topic 79:\n",
      "enters rotation wool byte sun\n",
      "Topic 80:\n",
      "pound xrays butter buttermilk diamond\n",
      "Topic 81:\n",
      "expert olympics horse silver medal\n",
      "Topic 82:\n",
      "weather thursday leech child johnny\n",
      "Topic 83:\n",
      "breath waste supermarket dolphin bake\n",
      "Topic 84:\n",
      "comet halley bc panda cupcake\n",
      "Topic 85:\n",
      "birth place date mouse baby\n",
      "Topic 86:\n",
      "feel snail sleep year frigate\n",
      "Topic 87:\n",
      "fry rhombicuboctahedron access chicken side\n",
      "Topic 88:\n",
      "mar potential trade indicator gdp\n",
      "Topic 89:\n",
      "champagne sea chef cook way\n",
      "Topic 90:\n",
      "watch group metallica travel gymnastics\n",
      "Topic 91:\n",
      "story digit claim mention maker\n",
      "Topic 92:\n",
      "day speed mph saturn website\n",
      "Topic 93:\n",
      "internet forum view reason family\n",
      "Topic 94:\n",
      "today usd industrialist outage line\n",
      "Topic 95:\n",
      "record cricket match beatles day\n",
      "Topic 96:\n",
      "letter doesnt understands space name\n",
      "Topic 97:\n",
      "brain activity alters weight gorilla\n",
      "Topic 98:\n",
      "avocado quintillion air pound admit\n",
      "Topic 99:\n",
      "population time human tank jet\n"
     ]
    }
   ],
   "source": [
    "# Displaying topics\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "# Displaying topics for the TF-IDF model\n",
    "display_topics(lda_tfidf, tfidf_vectorizer.get_feature_names_out(), 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   processed_text  topic\n",
      "0                           drone delivery become     91\n",
      "1              microorganism teaspoon soil planet     34\n",
      "2                         industrialist usd today     94\n",
      "3                 metro st petersburg depth metro     29\n",
      "4           business employee workplace worldwide     43\n",
      "5   product gdp indicator country trade potential     88\n",
      "6    elvis presley sell record music band beatles     95\n",
      "7                                christmas crosby     11\n",
      "8         half world population access web device     68\n",
      "9                         drive store work create     24\n",
      "10                                spends internet     63\n",
      "11                            generates byte data     79\n",
      "12                       record cricket match day     95\n",
      "13                          event summer olympics     42\n",
      "14        basketball legend wilt chamberlain game     38\n",
      "15             city bus network jakarta indonesia     62\n",
      "16                                      dog sense     40\n",
      "17                             garden snail teeth     60\n",
      "18                                           moon     45\n",
      "19                                      moon part      6\n",
      "Unique Topic:  100\n"
     ]
    }
   ],
   "source": [
    "topic_results = lda_tfidf.transform(tfidf_data_vectorized)\n",
    "df_text['topic'] = topic_results.argmax(axis=1)\n",
    "print(df_text[['processed_text','topic']].head(20))\n",
    "print(\"Unique Topic: \", len(df_text['topic'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually assign topic label\n",
    "topic_labels = [\n",
    "    \"Global Entrepreneurship\", # Topic 0\n",
    "    \"Eggshell Protection\",    # Topic 1\n",
    "    \"Astronomical Biology\",    # Topic 2\n",
    "    \"Animal Communication\",    # Topic 3\n",
    "    \"Nature Flavor & Length\",         # Topic 4\n",
    "    \"Fear & Sleep\",            # Topic 5\n",
    "    \"Cosmic Components\",       # Topic 6\n",
    "    \"Shipping & Food\",         # Topic 7\n",
    "    \"Organic Materials\",          # Topic 8\n",
    "    \"Operational Mechanics\",   # Topic 9\n",
    "    \"Traffic & Bathwater\",     # Topic 10\n",
    "    \"Musical Christmas\",       # Topic 11\n",
    "    \"Food & Sailing\",          # Topic 12\n",
    "    \"Sporting Records\",        # Topic 13\n",
    "    \"Butterfly Baseball\",      # Topic 14\n",
    "    \"Dance & Mosquitoes\",      # Topic 15\n",
    "    \"Radio & Invention\",       # Topic 16\n",
    "    \"Language & Geography\",    # Topic 17\n",
    "    \"Telecommunication\",       # Topic 18\n",
    "    \"Astronomical Vision\",     # Topic 19\n",
    "    \"Solar System\",            # Topic 20\n",
    "    \"Architectural Invention\", # Topic 21\n",
    "    \"Aquatic Terrain\",         # Topic 22\n",
    "    \"Keyboard & Alaska\",     # Topic 23\n",
    "    \"Protective Storage\",      # Topic 24\n",
    "    \"Animal Transport\",        # Topic 25\n",
    "    \"Botanical Sports\",        # Topic 26\n",
    "    \"Water Communication\",     # Topic 27\n",
    "    \"Desert Candy\",            # Topic 28\n",
    "    \"Distance Predictions\",     # Topic 29\n",
    "    \"Industrial Employment\",   # Topic 30\n",
    "    \"Animal Emotion\",          # Topic 31\n",
    "    \"Hair Weight\",             # Topic 32\n",
    "    \"Botanical Physics\",       # Topic 33\n",
    "    \"Microbial Planets\",       # Topic 34\n",
    "    \"Aquatic Anatomy\",         # Topic 35\n",
    "    \"Connective Mileage\",      # Topic 36\n",
    "    \"Avian Typing\",            # Topic 37\n",
    "    \"Strategic Games\",         # Topic 38\n",
    "    \"Aquatic Survival\",        # Topic 39\n",
    "    \"Sense Product\",           # Topic 40\n",
    "    \"Travel & Pineapple\",      # Topic 41\n",
    "    \"Ocean Glow\",              # Topic 42\n",
    "    \"Business Sales\",          # Topic 43\n",
    "    \"Pyramid Physics\",         # Topic 44\n",
    "    \"Lunar Attraction\",        # Topic 45\n",
    "    \"Automotive Mileage\",      # Topic 46\n",
    "    \"Research Claims\",         # Topic 47\n",
    "    \"Language & Science\",      # Topic 48\n",
    "    \"Directional Ecology\",     # Topic 49\n",
    "    \"Sports & Mice\",           # Topic 50\n",
    "    \"Chemical & Family\",       # Topic 51\n",
    "    \"Tongue Printing\",         # Topic 52\n",
    "    \"Seasonal Coding\",         # Topic 53\n",
    "    \"Flight History\",          # Topic 54\n",
    "    \"Subway Naming\",           # Topic 55\n",
    "    \"Dream Physiology\",        # Topic 56\n",
    "    \"Cosmic Music\",            # Topic 57\n",
    "    \"Celestial Dice\",          # Topic 58\n",
    "    \"Rainy Planets\",           # Topic 59\n",
    "    \"Telescope Garden\",        # Topic 60\n",
    "    \"Online Flight\",           # Topic 61\n",
    "    \"Urban Networks\",          # Topic 62\n",
    "    \"Weekly Spending\",         # Topic 63\n",
    "    \"Orchestral Phrases\",      # Topic 64\n",
    "    \"Winter Chemistry\",        # Topic 65\n",
    "    \"Quantum Memory\",          # Topic 66\n",
    "    \"Daily Hygiene\",           # Topic 67\n",
    "    \"Space Heat & Population\", # Topic 68\n",
    "    \"Rainbow Dessert\",         # Topic 69\n",
    "    \"Island Aging\",            # Topic 70\n",
    "    \"Electric Shooting\",       # Topic 71\n",
    "    \"Aerial Gymnastics\",       # Topic 72\n",
    "    \"Australasian Geography\",  # Topic 73\n",
    "    \"Bird Flights\",            # Topic 74\n",
    "    \"Plant Growth\",            # Topic 75\n",
    "    \"Predator Construction\",   # Topic 76\n",
    "    \"Culinary Beliefs\",        # Topic 77\n",
    "    \"Planetary Hooks\",         # Topic 78\n",
    "    \"Fiber Connectivity\",      # Topic 79\n",
    "    \"Diamond X-Rays\",          # Topic 80\n",
    "    \"Equestrian Olympics\",     # Topic 81\n",
    "    \"Weather & Childhood\",     # Topic 82\n",
    "    \"Breath & Waste\",        # Topic 83\n",
    "    \"Historic Comet\",          # Topic 84\n",
    "    \"Birth & Mice\",            # Topic 85\n",
    "    \"Snail Sleep\",             # Topic 86\n",
    "    \"Chicken Geometry\",        # Topic 87\n",
    "    \"Economic Indicators\",     # Topic 88\n",
    "    \"Champagne Cooking\",       # Topic 89\n",
    "    \"Travel & Music\",          # Topic 90\n",
    "    \"Maker\",                   # Topic 91\n",
    "    \"Speedy Website\",          # Topic 92\n",
    "    \"Internet Forum\",          # Topic 93\n",
    "    \"Industrial Outage\",       # Topic 94\n",
    "    \"Music & Cricket\",         # Topic 95\n",
    "    \"Space & Literacy\",        # Topic 96\n",
    "    \"Cognitive Weight\",        # Topic 97\n",
    "    \"Airborne Avocado\",        # Topic 98\n",
    "    \"Population Dynamics\"      # Topic 99\n",
    "]\n",
    "\n",
    "len(topic_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       processed_text              topic_label\n",
      "19064                                 change size age             Island Aging\n",
      "19065                                   leech weather      Weather & Childhood\n",
      "19066                              melt glacier noise        Keyboard & Alaska\n",
      "19067                    weight alters brain activity         Cognitive Weight\n",
      "19068                          fold chef way cook egg        Champagne Cooking\n",
      "19069                               language language     Language & Geography\n",
      "19070                              predict earthquake     Distance Predictions\n",
      "19071                                cat taste flavor   Nature Flavor & Length\n",
      "19072             banana curve shape grow towards sun  Global Entrepreneurship\n",
      "19073                              apple seed cyanide         Winter Chemistry\n",
      "19074                                 spends day item          Weekly Spending\n",
      "19075                        squirrel roam land india       Connective Mileage\n",
      "19076                            sloth breath dolphin           Breath & Waste\n",
      "19077                                           brain         Cognitive Weight\n",
      "19078  amount pressure surface area egg prevent break      Eggshell Protection\n",
      "19079                           quintillion pound air         Airborne Avocado\n",
      "19080                                     colony year       Language & Science\n",
      "19081                                       moon move     Astronomical Biology\n",
      "19082                                     strike time        Telecommunication\n",
      "19083                       pineapple plant pineapple       Travel & Pineapple\n"
     ]
    }
   ],
   "source": [
    "assert len(df_text['topic'].unique()) <= len(topic_labels), \"There are more unique topics than labels provided.\"\n",
    "df_text['topic_label'] = df_text['topic'].map(lambda x: topic_labels[x])\n",
    "print(df_text[['processed_text', 'topic_label']].tail(20))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    topic              topic_label          mean  count           std\n",
      "0      93           Internet Forum  30241.510791    139  37919.180900\n",
      "1      38          Strategic Games  27043.565476    168  35880.836428\n",
      "2      47          Research Claims  25488.409283    237  36327.257574\n",
      "3      81      Equestrian Olympics  21119.884422    199  32993.608451\n",
      "4       3     Animal Communication  20900.545455    165  35906.481602\n",
      "5      68  Space Heat & Population  20336.335000    200  38854.104602\n",
      "6      65         Winter Chemistry  19861.581081    222  34054.713667\n",
      "7      73   Australasian Geography  19822.168000    250  38023.239439\n",
      "8      60         Telescope Garden  19536.644351    239  38049.117636\n",
      "9      26         Botanical Sports  19528.946721    244  37662.679697\n",
      "10     87         Chicken Geometry  19475.753695    203  34888.696050\n",
      "11     19      Astronomical Vision  19368.335714    280  34258.194311\n",
      "12      7          Shipping & Food  19352.926087    230  38656.339057\n",
      "13     36       Connective Mileage  19342.798658    149  35191.338256\n",
      "14     15       Dance & Mosquitoes  19308.977612    134  37292.960479\n",
      "15     24       Protective Storage  19287.304348    161  32534.267156\n",
      "16     45         Lunar Attraction  19259.456954    151  38796.470958\n",
      "17     48       Language & Science  19195.564014    289  38108.133008\n",
      "18     72        Aerial Gymnastics  19179.204301    186  35421.332627\n",
      "19     14       Butterfly Baseball  19042.437500    224  35283.346041\n",
      "20     67            Daily Hygiene  18861.263566    129  35928.333741\n",
      "21      6        Cosmic Components  18706.362573    171  34950.003636\n",
      "22     21  Architectural Invention  18638.348739    238  32764.784331\n",
      "23     90           Travel & Music  18435.002882    347  35775.093728\n",
      "24     17     Language & Geography  18430.221622    185  36194.067357\n",
      "25     32              Hair Weight  18338.266667     60  28301.113316\n",
      "26     52          Tongue Printing  18316.857143    238  33465.368457\n",
      "27     91                    Maker  18307.594595    222  32304.608103\n",
      "28     70             Island Aging  18127.552239    134  31448.668348\n",
      "29     12           Food & Sailing  17930.772222    180  34963.597256\n",
      "30     22          Aquatic Terrain  17837.418231    373  33401.550617\n",
      "31     84           Historic Comet  17718.621212    198  34841.492442\n",
      "32     31           Animal Emotion  17675.883721    129  31937.435700\n",
      "33     61            Online Flight  17474.166667      6  19092.105022\n",
      "34     55            Subway Naming  17463.384236    203  32623.848482\n",
      "35     20             Solar System  17101.596154    208  34951.761998\n",
      "36     39         Aquatic Survival  16872.337607    234  32608.527618\n",
      "37     98         Airborne Avocado  16827.094340    106  29642.976210\n",
      "38     10      Traffic & Bathwater  16800.541401    157  30869.442726\n",
      "39     88      Economic Indicators  16652.218650    311  33378.299630\n",
      "40     76    Predator Construction  16648.081522    184  32340.028519\n",
      "41     56         Dream Physiology  16565.396296    270  31487.786775\n",
      "42     11        Musical Christmas  16494.389313    131  32104.301140\n",
      "43     27      Water Communication  16438.830882    136  29832.962232\n",
      "44     16        Radio & Invention  16361.192171    281  28323.044691\n",
      "45     30    Industrial Employment  16248.393651    315  30256.798473\n",
      "46     83           Breath & Waste  16229.876596    235  31762.298364\n",
      "47     85             Birth & Mice  16201.548077    208  30351.778555\n",
      "48     79       Fiber Connectivity  16190.650602    249  30649.594494\n",
      "49     77         Culinary Beliefs  16182.439394    132  33907.519270\n",
      "50     74             Bird Flights  16174.837438    203  30121.740458\n",
      "51     46       Automotive Mileage  16164.378151    119  29881.445297\n",
      "52     28             Desert Candy  16104.937107    159  31667.884721\n",
      "53     97         Cognitive Weight  16059.136986    219  30244.872912\n",
      "54     37             Avian Typing  16002.801418    141  29951.374044\n",
      "55     89        Champagne Cooking  15979.172932    133  32111.666951\n",
      "56     80           Diamond X-Rays  15931.900585    171  28292.027255\n",
      "57     35          Aquatic Anatomy  15909.496732    153  28630.688286\n",
      "58     57             Cosmic Music  15899.908730    252  33049.337545\n",
      "59     64       Orchestral Phrases  15882.391304    184  30635.778006\n",
      "60     50            Sports & Mice  15754.632867    286  32570.742422\n",
      "61     95          Music & Cricket  15727.386861    137  31380.688432\n",
      "62     63          Weekly Spending  15720.374269    171  30200.102718\n",
      "63     92           Speedy Website  15697.500000     70  30431.692739\n",
      "64     44          Pyramid Physics  15639.448087    183  28885.103389\n",
      "65     53          Seasonal Coding  15508.128205    117  32818.479516\n",
      "66     82      Weather & Childhood  15325.267045    176  28630.025931\n",
      "67     71        Electric Shooting  15293.622378    143  30423.092089\n",
      "68     58           Celestial Dice  15234.226667    225  27262.091692\n",
      "69     99      Population Dynamics  15063.037634    186  26096.116153\n",
      "70     96         Space & Literacy  14995.789157    332  31168.922184\n",
      "71      4   Nature Flavor & Length  14990.385593    236  29015.069415\n",
      "72     43           Business Sales  14990.285714    308  32088.703929\n",
      "73     25         Animal Transport  14947.031250    192  29027.990724\n",
      "74      8        Organic Materials  14943.366935    248  29259.641857\n",
      "75     23        Keyboard & Alaska  14897.753247    154  28255.578741\n",
      "76     13         Sporting Records  14708.813433    134  26430.775307\n",
      "77     78          Planetary Hooks  14685.362245    196  31520.003785\n",
      "78     41       Travel & Pineapple  14519.711340    291  32675.097692\n",
      "79     42               Ocean Glow  14487.550000    240  28872.510945\n",
      "80     69          Rainbow Dessert  14439.200000    175  29017.088136\n",
      "81     94        Industrial Outage  14369.304688    128  29368.481174\n",
      "82      9    Operational Mechanics  14307.095238    189  26871.703921\n",
      "83     75             Plant Growth  14232.934673    199  28017.222080\n",
      "84      2     Astronomical Biology  14139.400966    207  28728.144890\n",
      "85     86              Snail Sleep  14042.704225     71  25119.441646\n",
      "86      1      Eggshell Protection  13959.151316    152  32403.373207\n",
      "87     54           Flight History  13637.068182    176  30164.306897\n",
      "88     29     Distance Predictions  13568.982143    224  27898.717251\n",
      "89     34        Microbial Planets  13390.477612     67  32509.281830\n",
      "90      0  Global Entrepreneurship  13332.906250    256  28129.084009\n",
      "91     62           Urban Networks  13275.872928    181  28708.177676\n",
      "92     33        Botanical Physics  12941.490446    157  25663.073861\n",
      "93      5             Fear & Sleep  12917.318750    160  25197.536934\n",
      "94     18        Telecommunication  12615.761702    235  24845.572971\n",
      "95     40            Sense Product  12594.569106    246  28676.870182\n",
      "96     49      Directional Ecology  11935.756250    160  25233.532378\n",
      "97     59            Rainy Planets  11924.061069    131  24548.397092\n",
      "98     66           Quantum Memory  11309.687500    112  25737.698593\n",
      "99     51        Chemical & Family   9821.016949     59  20300.670882\n"
     ]
    }
   ],
   "source": [
    "grouped_stats = df_text.groupby(['topic', 'topic_label'])['video_share_count'].agg(['mean', 'count', 'std'])\n",
    "sorted_stats = grouped_stats.sort_values(by='mean', ascending=False).reset_index()\n",
    "print(sorted_stats)\n",
    "sorted_stats.to_csv('sorted_stats.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def plot_topic_histograms(topics, df, file_name, color):\n",
    "    n_rows = len(topics) // 5 + (len(topics) % 5 > 0)\n",
    "    fig, axes = plt.subplots(n_rows, 5, figsize=(20, 4 * n_rows), constrained_layout=True)\n",
    "\n",
    "    for i, topic in enumerate(topics):\n",
    "        ax = axes[i // 5, i % 5] if n_rows > 1 else axes[i % 5]\n",
    "        topic_data = df[df['topic'] == topic]\n",
    "        sns.histplot(data=topic_data, x='video_share_count', ax=ax, binwidth=1000, color=color, kde=False)\n",
    "        ax.set_title(topic_data['topic_label'].iloc[0])\n",
    "        ax.set_xlabel('Share Count')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    #plt.show()\n",
    "    plt.savefig(file_name)\n",
    "    plt.close()\n",
    "\n",
    "mean_shares = df_text.groupby('topic')['video_share_count'].mean().sort_values(ascending=False)\n",
    "sorted_topics = mean_shares.index.tolist()\n",
    "top_10_topics = sorted_topics[:10]\n",
    "plot_topic_histograms(top_10_topics, df_text, \"chart/top_10_topics.png\", color=\"#10BFBF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "last_10_topics = sorted_topics[-10:]\n",
    "plot_topic_histograms(last_10_topics, df_text, \"chart/last_10_topics_histogram.png\", color=\"#EE1D52\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}